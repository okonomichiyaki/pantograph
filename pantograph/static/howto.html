                <h2>how does it work?</h2>
                <p>
                    When you click on your opponent's video feed, an image is captured and sent to the backend,
                    where optical character recognition and fuzzy text search are used to find the title of the card.
                </p>
                <p style="font-style: italic; font-size: 0.75em">
                    (no image recognition is involved.
                    if you are proficient in computer vision or machine learning
                    and are interested in collaborating, please get in touch!)
                </p>

                <h2>why won't it recognize cards?</h2>
                <p>
                    You need a camera capable of capturing at least 720p video with an overhead shot of your play area.
                    The best way to improve the accuracy is to play in a well lit space with indirect lighting.
                    Direct light and glare that washes out the text on cards will hinder recognition.
                    Matte card sleeves may work better than glossy sleeves.
                </p>
                <p>
                    If you haven't already, be sure click the "calibrate" button and drag select a rectangle around any card on your opponent's video feed. You should repeat this process in a new room or if your opponent's video changes. (if it zooms in/out or moves closer/farther away from their table)
                </p>
                <p>
                    If you are playing Standard, you must create the room with that setting, otherwise only Startup cards will be searched for.
                    Players should join as the side they are playing, and either create a new room, or leave and rejoin to switch sides if you play a second game.
                    (this improves identification by narrowing the search space)
                    Both FFG and NSG cards are supported, but alt arts with unusual templating may not work.
                </p>

